{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b0fa2d",
   "metadata": {},
   "source": [
    "Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9d50c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spotipy\n",
      "  Downloading spotipy-2.19.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.9/site-packages (from spotipy) (1.26.7)\n",
      "Requirement already satisfied: six>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spotipy) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in /opt/conda/lib/python3.9/site-packages (from spotipy) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (2021.5.30)\n",
      "Installing collected packages: spotipy\n",
      "Successfully installed spotipy-2.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# First set up the environment. Code sources are in folders which are in the parent folder of this notebooks scope.\n",
    "import sys; sys.path.insert(0, '..') # add parent folder path, now files are queriable from parent folder\n",
    "\n",
    "%pip install spotipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ab1cf",
   "metadata": {},
   "source": [
    "Create train test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede42b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the downloaded data\n",
    "from data.query.util import loadJson\n",
    "\n",
    "notHitSongPath = '../data/datasets/spotify/not_hit_song.json'\n",
    "hitSongPath = '../data/datasets/spotify/hit_song.json'\n",
    "\n",
    "# Load the data\n",
    "hits = loadJson(hitSongPath)\n",
    "notHits = loadJson(notHitSongPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb226fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data.plotting.util import makeHistogram\n",
    "\n",
    "# Here is the number of hits and not hits\n",
    "makeHistogram([0, 1], [len(notHits), len(hits)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c9f7a",
   "metadata": {},
   "source": [
    "The hits data will be collected and stored in a pandas dataframe for further sampling and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d23a921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeSignature</th>\n",
       "      <th>durationMS</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>164442</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00323</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>-5.187</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.695</td>\n",
       "      <td>109.997</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>178147</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.33500</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>-5.044</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.688</td>\n",
       "      <td>166.928</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>203808</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05610</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>-2.278</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.914</td>\n",
       "      <td>103.014</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>137704</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.29300</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>-6.725</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.710</td>\n",
       "      <td>178.781</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>231041</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04690</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.3640</td>\n",
       "      <td>-3.712</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.591</td>\n",
       "      <td>126.026</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19457</th>\n",
       "      <td>4</td>\n",
       "      <td>141107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85800</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3090</td>\n",
       "      <td>-8.703</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.653</td>\n",
       "      <td>157.198</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19458</th>\n",
       "      <td>4</td>\n",
       "      <td>159293</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74300</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>-15.080</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.305</td>\n",
       "      <td>78.674</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19459</th>\n",
       "      <td>4</td>\n",
       "      <td>510960</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93100</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>-20.173</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.192</td>\n",
       "      <td>73.157</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19460</th>\n",
       "      <td>4</td>\n",
       "      <td>152200</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.43200</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>-12.023</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.686</td>\n",
       "      <td>116.528</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19461</th>\n",
       "      <td>4</td>\n",
       "      <td>154173</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65800</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>-7.528</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.345</td>\n",
       "      <td>69.182</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19462 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timeSignature  durationMS  key  mode  acousticness  danceability  \\\n",
       "0                  4      164442    8     1       0.00323         0.759   \n",
       "1                  4      178147    9     1       0.33500         0.563   \n",
       "2                  4      203808    6     0       0.05610         0.695   \n",
       "3                  4      137704    8     0       0.29300         0.593   \n",
       "4                  4      231041   11     0       0.04690         0.808   \n",
       "...              ...         ...  ...   ...           ...           ...   \n",
       "19457              4      141107    0     1       0.85800         0.543   \n",
       "19458              4      159293    5     1       0.74300         0.560   \n",
       "19459              4      510960    0     1       0.93100         0.203   \n",
       "19460              4      152200    8     1       0.43200         0.744   \n",
       "19461              4      154173    5     1       0.65800         0.242   \n",
       "\n",
       "       energy  instrumentalness  liveness  loudness  speechiness  valence  \\\n",
       "0       0.459          0.000000    0.0906    -5.187       0.0948    0.695   \n",
       "1       0.664          0.000000    0.0849    -5.044       0.1540    0.688   \n",
       "2       0.884          0.000000    0.2130    -2.278       0.0753    0.914   \n",
       "3       0.503          0.000000    0.4050    -6.725       0.2200    0.710   \n",
       "4       0.897          0.000031    0.3640    -3.712       0.0348    0.591   \n",
       "...       ...               ...       ...       ...          ...      ...   \n",
       "19457   0.560          0.000000    0.3090    -8.703       0.1170    0.653   \n",
       "19458   0.270          0.000346    0.1720   -15.080       0.0412    0.305   \n",
       "19459   0.156          0.788000    0.0910   -20.173       0.0343    0.192   \n",
       "19460   0.508          0.000320    0.0808   -12.023       0.1150    0.686   \n",
       "19461   0.436          0.000000    0.3240    -7.528       0.0367    0.345   \n",
       "\n",
       "         tempo year  \n",
       "0      109.997   21  \n",
       "1      166.928   21  \n",
       "2      103.014   21  \n",
       "3      178.781   21  \n",
       "4      126.026   21  \n",
       "...        ...  ...  \n",
       "19457  157.198   20  \n",
       "19458   78.674   66  \n",
       "19459   73.157   93  \n",
       "19460  116.528   86  \n",
       "19461   69.182   58  \n",
       "\n",
       "[19462 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from data.process.util import parseYearFromDate\n",
    "\n",
    "features = []\n",
    "for hit in hits:\n",
    "    year = parseYearFromDate(hit['info']['spotifyData']['album']['releaseDate'])\n",
    "    features.append({**hit['features'], 'year': year[2:]})\n",
    "\n",
    "hitsDataset = DataFrame.from_records(features)\n",
    "hitsDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160c97f",
   "metadata": {},
   "source": [
    "Now the same to not hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bc2efc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeSignature</th>\n",
       "      <th>durationMS</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>258004</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00173</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-4.668</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.468</td>\n",
       "      <td>115.982</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>203064</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00883</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0674</td>\n",
       "      <td>-3.787</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.915</td>\n",
       "      <td>102.977</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>195352</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01850</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>-6.254</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.570</td>\n",
       "      <td>114.986</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>221820</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16700</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>-3.434</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.467</td>\n",
       "      <td>113.011</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>200108</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00450</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>-4.966</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.420</td>\n",
       "      <td>113.213</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73557</th>\n",
       "      <td>3</td>\n",
       "      <td>167867</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82700</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>-9.549</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.516</td>\n",
       "      <td>108.041</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73558</th>\n",
       "      <td>4</td>\n",
       "      <td>169240</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44700</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2980</td>\n",
       "      <td>-6.526</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.873</td>\n",
       "      <td>84.345</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73559</th>\n",
       "      <td>4</td>\n",
       "      <td>138160</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61700</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>-5.329</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.803</td>\n",
       "      <td>183.350</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73560</th>\n",
       "      <td>4</td>\n",
       "      <td>107467</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72800</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>-8.466</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.896</td>\n",
       "      <td>160.928</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73561</th>\n",
       "      <td>4</td>\n",
       "      <td>127200</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.55900</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>-8.968</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.795</td>\n",
       "      <td>116.831</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73562 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timeSignature  durationMS  key  mode  acousticness  danceability  \\\n",
       "0                  4      258004   11     0       0.00173         0.659   \n",
       "1                  4      203064    6     0       0.00883         0.702   \n",
       "2                  4      195352    5     1       0.01850         0.809   \n",
       "3                  4      221820    4     0       0.16700         0.730   \n",
       "4                  4      200108   11     0       0.00450         0.640   \n",
       "...              ...         ...  ...   ...           ...           ...   \n",
       "73557              3      167867    5     1       0.82700         0.465   \n",
       "73558              4      169240    5     1       0.44700         0.664   \n",
       "73559              4      138160    5     1       0.61700         0.576   \n",
       "73560              4      107467    3     1       0.72800         0.574   \n",
       "73561              4      127200    2     1       0.55900         0.691   \n",
       "\n",
       "       energy  instrumentalness  liveness  loudness  speechiness  valence  \\\n",
       "0       0.667          0.000029    0.1000    -4.668       0.0339    0.468   \n",
       "1       0.825          0.000000    0.0674    -3.787       0.0601    0.915   \n",
       "2       0.623          0.000088    0.0538    -6.254       0.1450    0.570   \n",
       "3       0.729          0.000001    0.3490    -3.434       0.0884    0.467   \n",
       "4       0.665          0.000000    0.2200    -4.966       0.0325    0.420   \n",
       "...       ...               ...       ...       ...          ...      ...   \n",
       "73557   0.342          0.000000    0.2520    -9.549       0.0301    0.516   \n",
       "73558   0.660          0.000000    0.2980    -6.526       0.1300    0.873   \n",
       "73559   0.725          0.000027    0.2370    -5.329       0.0909    0.803   \n",
       "73560   0.560          0.000000    0.2460    -8.466       0.0502    0.896   \n",
       "73561   0.427          0.000000    0.1360    -8.968       0.0349    0.795   \n",
       "\n",
       "         tempo year  \n",
       "0      115.982   21  \n",
       "1      102.977   21  \n",
       "2      114.986   21  \n",
       "3      113.011   21  \n",
       "4      113.213   21  \n",
       "...        ...  ...  \n",
       "73557  108.041   58  \n",
       "73558   84.345   58  \n",
       "73559  183.350   58  \n",
       "73560  160.928   58  \n",
       "73561  116.831   58  \n",
       "\n",
       "[73562 rows x 14 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "for notHit in notHits:\n",
    "    year = parseYearFromDate(notHit['info']['spotifyData']['album']['releaseDate'])\n",
    "    features.append({**notHit['features'], 'year': year[2:]})\n",
    "\n",
    "notHitsDataset = DataFrame.from_records(features)\n",
    "notHitsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "57cd5e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now labels in place\n",
    "hitsDataset['label'] = 1\n",
    "notHitsDataset['label'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b2bad0",
   "metadata": {},
   "source": [
    "A few datasets will be created for testing purposes.\n",
    "\n",
    "Dataset 1 will have evenly among years sampled number of hit and not hits.\n",
    "\n",
    "Dataset 2 will be the same, The year feature will be dropped from the data given to the models. This is done to see the impact of the time information.\n",
    "\n",
    "Dataset 3 will be more focused on the later released songs by using only songs released 1985 or after.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e9fe8ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 00 Number of songs: 322\n",
      "Year: 01 Number of songs: 352\n",
      "Year: 02 Number of songs: 314\n",
      "Year: 03 Number of songs: 294\n",
      "Year: 04 Number of songs: 328\n",
      "Year: 05 Number of songs: 593\n",
      "Year: 06 Number of songs: 411\n",
      "Year: 07 Number of songs: 402\n",
      "Year: 08 Number of songs: 454\n",
      "Year: 09 Number of songs: 422\n",
      "Year: 10 Number of songs: 487\n",
      "Year: 11 Number of songs: 508\n",
      "Year: 12 Number of songs: 406\n",
      "Year: 13 Number of songs: 418\n",
      "Year: 14 Number of songs: 476\n",
      "Year: 15 Number of songs: 415\n",
      "Year: 16 Number of songs: 403\n",
      "Year: 17 Number of songs: 449\n",
      "Year: 18 Number of songs: 549\n",
      "Year: 19 Number of songs: 491\n",
      "Year: 20 Number of songs: 640\n",
      "Year: 21 Number of songs: 467\n",
      "Year: 42 Number of songs: 1\n",
      "Year: 45 Number of songs: 3\n",
      "Year: 47 Number of songs: 1\n",
      "Year: 50 Number of songs: 1\n",
      "Year: 52 Number of songs: 1\n",
      "Year: 53 Number of songs: 1\n",
      "Year: 54 Number of songs: 2\n",
      "Year: 56 Number of songs: 5\n",
      "Year: 57 Number of songs: 9\n",
      "Year: 58 Number of songs: 33\n",
      "Year: 59 Number of songs: 54\n",
      "Year: 60 Number of songs: 79\n",
      "Year: 61 Number of songs: 81\n",
      "Year: 62 Number of songs: 150\n",
      "Year: 63 Number of songs: 154\n",
      "Year: 64 Number of songs: 134\n",
      "Year: 65 Number of songs: 192\n",
      "Year: 66 Number of songs: 196\n",
      "Year: 67 Number of songs: 231\n",
      "Year: 68 Number of songs: 250\n",
      "Year: 69 Number of songs: 240\n",
      "Year: 70 Number of songs: 230\n",
      "Year: 71 Number of songs: 223\n",
      "Year: 72 Number of songs: 244\n",
      "Year: 73 Number of songs: 274\n",
      "Year: 74 Number of songs: 225\n",
      "Year: 75 Number of songs: 296\n",
      "Year: 76 Number of songs: 278\n",
      "Year: 77 Number of songs: 231\n",
      "Year: 78 Number of songs: 238\n",
      "Year: 79 Number of songs: 224\n",
      "Year: 80 Number of songs: 202\n",
      "Year: 81 Number of songs: 240\n",
      "Year: 82 Number of songs: 232\n",
      "Year: 83 Number of songs: 237\n",
      "Year: 84 Number of songs: 226\n",
      "Year: 85 Number of songs: 256\n",
      "Year: 86 Number of songs: 250\n",
      "Year: 87 Number of songs: 269\n",
      "Year: 88 Number of songs: 271\n",
      "Year: 89 Number of songs: 317\n",
      "Year: 90 Number of songs: 292\n",
      "Year: 91 Number of songs: 352\n",
      "Year: 92 Number of songs: 284\n",
      "Year: 93 Number of songs: 341\n",
      "Year: 94 Number of songs: 254\n",
      "Year: 95 Number of songs: 292\n",
      "Year: 96 Number of songs: 310\n",
      "Year: 97 Number of songs: 277\n",
      "Year: 98 Number of songs: 332\n",
      "Year: 99 Number of songs: 346\n"
     ]
    }
   ],
   "source": [
    "for i, year in enumerate(sorted(hitsDataset['year'].unique())):\n",
    "    print(f\"Year: {year} Number of songs: {len(hitsDataset[hitsDataset['year'] == year])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465883af",
   "metadata": {},
   "source": [
    "To collect even amount of songs per year, all songs before 1965 will be ignored, because of the low amount of songs.\n",
    "\n",
    "The number of songs in the list released 1965 will be the sample size for every year. That's 192. Dataset 1 and 2 will use this sample size.\n",
    "\n",
    "Dataset 3 will ignore all songs before 1985, so the smallest number of songs released in a year after that is 1986 with 250 songs. This will be the sample size for Dataset 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b0ce2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "13db4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import concat, DataFrame\n",
    "\n",
    "sampleSize = 192\n",
    "eghtyFiveSampleSize = 250\n",
    "\n",
    "hitSamples = None\n",
    "notHitSamples = None\n",
    "hitSamples85 = None\n",
    "notHitSamples85 = None\n",
    "count = 0\n",
    "for year in hitsDataset['year'].unique():\n",
    "    if int(year) < 65 and int(year) > 21:\n",
    "        continue\n",
    "    allHitsInYear = hitsDataset[hitsDataset['year'] == year]\n",
    "    allNotHitsInYear = notHitsDataset[notHitsDataset['year'] == year]\n",
    "    \n",
    "    # Take the samples\n",
    "    hitSample = allHitsInYear.sample(sampleSize)\n",
    "    notHitSample = allNotHitsInYear.sample(sampleSize)\n",
    "    \n",
    "    hitSamples = hitSample if not isinstance(hitSamples, DataFrame) else concat([hitSamples, hitSample], ignore_index=True)\n",
    "    notHitSamples = notHitSample if not isinstance(notHitSamples, DataFrame) else concat([notHitSamples, notHitSample], ignore_index=True)\n",
    "    \n",
    "    if int(year) > 85 or int(year) < 22:\n",
    "        # Take the samples\n",
    "        hitSample = allHitsInYear.sample(eghtyFiveSampleSize)\n",
    "        notHitSample = allNotHitsInYear.sample(eghtyFiveSampleSize)\n",
    "        \n",
    "        hitSamples85 = hitSample if not isinstance(hitSamples85, DataFrame) else concat([hitSamples85, hitSample], ignore_index=True)\n",
    "        notHitSamples85 = notHitSample if not isinstance(notHitSamples85, DataFrame) else concat([notHitSamples85, notHitSample], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d3914739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeSignature</th>\n",
       "      <th>durationMS</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>197800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>-6.965</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.487</td>\n",
       "      <td>99.991</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>278467</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.0777</td>\n",
       "      <td>-16.170</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.696</td>\n",
       "      <td>124.369</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>193455</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>-9.609</td>\n",
       "      <td>0.4730</td>\n",
       "      <td>0.705</td>\n",
       "      <td>77.057</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>155627</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>-11.465</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.722</td>\n",
       "      <td>81.338</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>190680</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>-5.254</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.367</td>\n",
       "      <td>88.003</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21883</th>\n",
       "      <td>4</td>\n",
       "      <td>159333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>-10.031</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.930</td>\n",
       "      <td>131.196</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21884</th>\n",
       "      <td>4</td>\n",
       "      <td>139733</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>-8.217</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.575</td>\n",
       "      <td>110.421</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21885</th>\n",
       "      <td>3</td>\n",
       "      <td>187493</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>-8.281</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.500</td>\n",
       "      <td>183.519</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21886</th>\n",
       "      <td>4</td>\n",
       "      <td>194333</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>-16.043</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.964</td>\n",
       "      <td>122.091</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21887</th>\n",
       "      <td>4</td>\n",
       "      <td>147467</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>-9.348</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.755</td>\n",
       "      <td>137.920</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21888 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timeSignature  durationMS  key  mode  acousticness  danceability  \\\n",
       "0                  4      197800    1     1         0.278         0.657   \n",
       "1                  4      278467    0     1         0.127         0.611   \n",
       "2                  1      193455    1     1         0.415         0.424   \n",
       "3                  3      155627   10     1         0.662         0.505   \n",
       "4                  4      190680    8     1         0.723         0.532   \n",
       "...              ...         ...  ...   ...           ...           ...   \n",
       "21883              4      159333    0     1         0.265         0.547   \n",
       "21884              4      139733    6     1         0.313         0.558   \n",
       "21885              3      187493    8     1         0.276         0.238   \n",
       "21886              4      194333    7     1         0.623         0.652   \n",
       "21887              4      147467    7     1         0.260         0.543   \n",
       "\n",
       "       energy  instrumentalness  liveness  loudness  speechiness  valence  \\\n",
       "0       0.715          0.000146    0.0838    -6.965       0.0273    0.487   \n",
       "1       0.479          0.000274    0.0777   -16.170       0.0364    0.696   \n",
       "2       0.511          0.000000    0.7050    -9.609       0.4730    0.705   \n",
       "3       0.299          0.000000    0.2450   -11.465       0.0276    0.722   \n",
       "4       0.584          0.000000    0.1010    -5.254       0.0248    0.367   \n",
       "...       ...               ...       ...       ...          ...      ...   \n",
       "21883   0.547          0.000000    0.1210   -10.031       0.0470    0.930   \n",
       "21884   0.595          0.000000    0.0815    -8.217       0.0383    0.575   \n",
       "21885   0.549          0.118000    0.3230    -8.281       0.0327    0.500   \n",
       "21886   0.426          0.000004    0.3520   -16.043       0.0598    0.964   \n",
       "21887   0.539          0.115000    0.2780    -9.348       0.0338    0.755   \n",
       "\n",
       "         tempo year  label  \n",
       "0       99.991   21      1  \n",
       "1      124.369   21      1  \n",
       "2       77.057   21      1  \n",
       "3       81.338   21      1  \n",
       "4       88.003   21      1  \n",
       "...        ...  ...    ...  \n",
       "21883  131.196   67      0  \n",
       "21884  110.421   67      0  \n",
       "21885  183.519   67      0  \n",
       "21886  122.091   67      0  \n",
       "21887  137.920   67      0  \n",
       "\n",
       "[21888 rows x 15 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The hits and not hits can be concatenated to create the dataset\n",
    "fullSampleDataset = concat([hitSamples, notHitSamples], ignore_index=True)\n",
    "fullSampleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8eb5bcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullSampleDataset['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "26ec30ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeSignature</th>\n",
       "      <th>durationMS</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>245267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00282</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>-4.822</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.445</td>\n",
       "      <td>120.128</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>174253</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50600</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3470</td>\n",
       "      <td>-4.601</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.619</td>\n",
       "      <td>124.097</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>299240</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28100</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>-5.232</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.171</td>\n",
       "      <td>101.019</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>248013</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>-8.382</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.650</td>\n",
       "      <td>115.804</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>125153</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.39800</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>-14.174</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.974</td>\n",
       "      <td>147.777</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>4</td>\n",
       "      <td>216933</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01350</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>-8.158</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.569</td>\n",
       "      <td>114.925</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>4</td>\n",
       "      <td>138373</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10300</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>-7.814</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.928</td>\n",
       "      <td>130.067</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>4</td>\n",
       "      <td>199573</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.55200</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>-15.826</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.126</td>\n",
       "      <td>129.552</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>4</td>\n",
       "      <td>121307</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>-10.767</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.946</td>\n",
       "      <td>123.202</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>4</td>\n",
       "      <td>281147</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>-9.390</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.559</td>\n",
       "      <td>143.905</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timeSignature  durationMS  key  mode  acousticness  danceability  \\\n",
       "0                  4      245267    0     1       0.00282         0.414   \n",
       "1                  4      174253    3     1       0.50600         0.855   \n",
       "2                  4      299240    2     1       0.28100         0.883   \n",
       "3                  4      248013    7     1       0.00300         0.583   \n",
       "4                  4      125153    8     1       0.39800         0.543   \n",
       "...              ...         ...  ...   ...           ...           ...   \n",
       "17995              4      216933    0     1       0.01350         0.840   \n",
       "17996              4      138373    0     1       0.10300         0.736   \n",
       "17997              4      199573    4     1       0.55200         0.411   \n",
       "17998              4      121307   11     0       0.72000         0.777   \n",
       "17999              4      281147   10     1       0.15200         0.521   \n",
       "\n",
       "       energy  instrumentalness  liveness  loudness  speechiness  valence  \\\n",
       "0       0.882          0.001520    0.0735    -4.822       0.0435    0.445   \n",
       "1       0.488          0.000000    0.3470    -4.601       0.2080    0.619   \n",
       "2       0.638          0.000006    0.0746    -5.232       0.0403    0.171   \n",
       "3       0.947          0.015400    0.1780    -8.382       0.0533    0.650   \n",
       "4       0.554          0.000038    0.2360   -14.174       0.0372    0.974   \n",
       "...       ...               ...       ...       ...          ...      ...   \n",
       "17995   0.859          0.000010    0.0689    -8.158       0.0712    0.569   \n",
       "17996   0.612          0.347000    0.0378    -7.814       0.0489    0.928   \n",
       "17997   0.202          0.000000    0.3050   -15.826       0.0321    0.126   \n",
       "17998   0.452          0.000000    0.1660   -10.767       0.0366    0.946   \n",
       "17999   0.540          0.000000    0.1060    -9.390       0.0287    0.559   \n",
       "\n",
       "         tempo year  label  \n",
       "0      120.128   21      1  \n",
       "1      124.097   21      1  \n",
       "2      101.019   21      1  \n",
       "3      115.804   21      1  \n",
       "4      147.777   21      1  \n",
       "...        ...  ...    ...  \n",
       "17995  114.925   93      0  \n",
       "17996  130.067   93      0  \n",
       "17997  129.552   93      0  \n",
       "17998  123.202   93      0  \n",
       "17999  143.905   93      0  \n",
       "\n",
       "[18000 rows x 15 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alsso, the hits and not hits can be concatenated to create the dataset for songs released after 1985\n",
    "afterEightyFiveSampleDataset = concat([hitSamples85, notHitSamples85], ignore_index=True)\n",
    "afterEightyFiveSampleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fde2c8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(afterEightyFiveSampleDataset['year'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca9372",
   "metadata": {},
   "source": [
    "Next step is to transform the data.\n",
    "\n",
    "The transformed values will be then used as the training and testing data.\n",
    "\n",
    "In the transformation, columns that are not in scale from 0 to 1 will be scaled into that interval. Columns that have categorical data will be OneHotEncoded, this means that as many as there are possible categories for a value, new columns are added. 1 indicates a row belonging to this category and all other columns will be set to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2be8ca44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('scale', MinMaxScaler(),\n",
       "                                 ['durationMS', 'loudness', 'tempo', 'year']),\n",
       "                                ('onehot', OneHotEncoder(),\n",
       "                                 ['timeSignature', 'key', 'mode'])])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize the transformer\n",
    "transformer = ColumnTransformer([ \n",
    "    (\"scale\", MinMaxScaler(), ['durationMS', 'loudness', 'tempo', 'year']),\n",
    "    (\"onehot\", OneHotEncoder(), ['timeSignature', 'key', 'mode'])\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "# Fit the transformer with the whole sampled dataset\n",
    "transformer.fit(fullSampleDataset.drop(['label'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "64facd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'one': transformer.transform(fullSampleDataset.drop(['label'], axis=1)),\n",
    "    'two': transformer.transform(fullSampleDataset.drop(['label'], axis=1))[:, :-1],\n",
    "    'three': transformer.transform(afterEightyFiveSampleDataset.drop(['label'], axis=1)),\n",
    "    'four': transformer.transform(afterEightyFiveSampleDataset.drop(['label'], axis=1))[:, :-1],\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    'one': fullSampleDataset.label,\n",
    "    'two': fullSampleDataset.label,\n",
    "    'three': afterEightyFiveSampleDataset.label,\n",
    "    'four': afterEightyFiveSampleDataset.label,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a91e0c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset one shape: (21888, 30) labels: (21888,)\n",
      "Dataset two shape: (21888, 29) labels: (21888,)\n",
      "Dataset three shape: (18000, 30) labels: (18000,)\n",
      "Dataset four shape: (18000, 29) labels: (18000,)\n"
     ]
    }
   ],
   "source": [
    "for dataset, s in datasets.items():\n",
    "    l = labels[dataset]\n",
    "    print(f\"Dataset {dataset} shape: {s.shape} labels: {l.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a9861f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17510, 30) (4378, 30) (17510,) (4378,)\n",
      "(17510, 29) (4378, 29) (17510,) (4378,)\n",
      "(14400, 30) (3600, 30) (14400,) (3600,)\n",
      "(14400, 29) (3600, 29) (14400,) (3600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "oneX_train, oneX_test, oneY_train, oneY_test = train_test_split(datasets['one'], labels['one'], test_size=0.2)\n",
    "twoX_train, twoX_test, twoY_train, twoY_test = train_test_split(datasets['two'], labels['two'], test_size=0.2)\n",
    "threeX_train, threeX_test, threeY_train, threeY_test = train_test_split(datasets['three'], labels['three'], test_size=0.2)\n",
    "fourX_train, fourX_test, fourY_train, fourY_test = train_test_split(datasets['four'], labels['four'], test_size=0.2)\n",
    "\n",
    "print(oneX_train.shape, oneX_test.shape, oneY_train.shape, oneY_test.shape)\n",
    "print(twoX_train.shape, twoX_test.shape, twoY_train.shape, twoY_test.shape)\n",
    "print(threeX_train.shape, threeX_test.shape, threeY_train.shape, threeY_test.shape)\n",
    "print(fourX_train.shape, fourX_test.shape, fourY_train.shape, fourY_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5899eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8831\n",
       "0    8679\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoY_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8944172",
   "metadata": {},
   "source": [
    "# Initialize models\n",
    "\n",
    "Most of the models need hyperparameters to be set. As the values for them are not totally clear, it is common to try multiple and use the best model measured by some performance measure.\n",
    "\n",
    "Scikit-learn GridSearch will be used. It takes in as parameters all the combinations of hyperparameters to test. It creates and fits the model one by one with all of the hyperparameter combinations. The best performing model is then usable as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "0e8bbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "groups = fullSampleDataset.label\n",
    "groupsEightyFive = afterEightyFiveSampleDataset.label\n",
    "group_kfold = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbea4162",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "3ece9fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results: One 0.6664211643576141 Two: 0.6648711689466795 Three: 0.6666666666666666 Four 0.6666666666666666\n",
      "Best params: \n",
      "One {'C': 1e-06, 'max_iter': 100, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'} \n",
      "Two: {'C': 1e-06, 'max_iter': 100, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'} \n",
      "Three: {'C': 1e-06, 'l1_ratio': 0.4, 'max_iter': 100000, 'multi_class': 'ovr', 'n_jobs': -1, 'penalty': 'elasticnet', 'solver': 'saga', 'warm_start': True} \n",
      "Four {'C': 0.0001, 'l1_ratio': 0.6, 'max_iter': 100000, 'multi_class': 'ovr', 'n_jobs': -1, 'penalty': 'elasticnet', 'solver': 'saga', 'warm_start': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'solver': ['liblinear'], \n",
    "        'penalty': ['l1', 'l2'],  \n",
    "        'multi_class': ['ovr'],\n",
    "        'max_iter': [100, 250, 500, 1000],\n",
    "        'C': [0.000001, 0.000001, 0.000001]\n",
    "    }, \n",
    "    {\n",
    "        'solver': ['saga'], \n",
    "        'penalty': ['elasticnet'], \n",
    "        'multi_class': ['ovr'], \n",
    "        'n_jobs': [-1], \n",
    "        'warm_start': [True],\n",
    "        'max_iter': [1000, 10000, 100000],\n",
    "        'C': [0.000001, 0.00001, 0.0001],\n",
    "        'l1_ratio': [0.4, 0.5, 0.6]\n",
    "    }, \n",
    "]\n",
    "\n",
    "# Classifier trained with dataset One\n",
    "logRegOne = GridSearchCV(LogisticRegression(), params, n_jobs=-1, scoring='f1')\n",
    "logRegOne.fit(datasets['one'], labels['one'], groups=groups)\n",
    "\n",
    "# Classifier trained with dataset Two\n",
    "logRegTwo = GridSearchCV(LogisticRegression(), params, n_jobs=-1, scoring='f1')\n",
    "logRegTwo.fit(datasets['two'], labels['two'], groups=groups)\n",
    "\n",
    "# Classifier trained with dataset Three\n",
    "logRegThree = GridSearchCV(LogisticRegression(), params, n_jobs=-1, scoring='f1')\n",
    "logRegThree.fit(datasets['three'], labels['three'], groups=groupsEightyFive)\n",
    "\n",
    "# Classifier trained with dataset Four\n",
    "logRegFour = GridSearchCV(LogisticRegression(), params, n_jobs=-1, scoring='f1')\n",
    "logRegFour.fit(datasets['four'], labels['four'], groups=groupsEightyFive)\n",
    "\n",
    "print(f\"Best results: One {logRegOne.best_score_} Two: {logRegTwo.best_score_} Three: {logRegThree.best_score_} Four {logRegFour.best_score_}\")\n",
    "\n",
    "print(f\"Best params: \\nOne {logRegOne.best_params_} \\nTwo: {logRegTwo.best_params_} \\nThree: {logRegThree.best_params_} \\nFour {logRegFour.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856da473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb7c34b0",
   "metadata": {},
   "source": [
    "Final model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "bdf4ce86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, l1_ratio=0.4, max_iter=100000, multi_class='ovr',\n",
       "                   n_jobs=-1, penalty='elasticnet', solver='saga',\n",
       "                   warm_start=True)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LRmodelOne = LogisticRegression(**{'C': 1e-06, 'max_iter': 100, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'})\n",
    "LRmodelTwo = LogisticRegression(**{'C': 1e-06, 'max_iter': 100, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'})\n",
    "LRmodelThree = LogisticRegression(**{'C': 1e-05, 'l1_ratio': 0.5, 'max_iter': 10000, 'multi_class': 'ovr', 'n_jobs': -1, 'penalty': 'elasticnet', 'solver': 'saga', 'warm_start': True})\n",
    "LRmodelFour = LogisticRegression(**{'C': 0.0001, 'l1_ratio': 0.4, 'max_iter': 100000, 'multi_class': 'ovr', 'n_jobs': -1, 'penalty': 'elasticnet', 'solver': 'saga', 'warm_start': True})\n",
    "\n",
    "# Train the models\n",
    "LRmodelOne.fit(oneX_train, oneY_train)\n",
    "LRmodelTwo.fit(twoX_train, twoY_train)\n",
    "LRmodelThree.fit(threeX_train, threeY_train)\n",
    "LRmodelFour.fit(fourX_train, fourY_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "30a71d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.00      0.00      2242\n",
      "           1       0.49      1.00      0.66      2136\n",
      "\n",
      "    accuracy                           0.49      4378\n",
      "   macro avg       0.62      0.50      0.33      4378\n",
      "weighted avg       0.62      0.49      0.32      4378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00      2265\n",
      "           1       0.48      1.00      0.65      2113\n",
      "\n",
      "    accuracy                           0.48      4378\n",
      "   macro avg       0.74      0.50      0.33      4378\n",
      "weighted avg       0.75      0.48      0.31      4378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66      1782\n",
      "           1       0.00      0.00      0.00      1818\n",
      "\n",
      "    accuracy                           0.49      3600\n",
      "   macro avg       0.25      0.50      0.33      3600\n",
      "weighted avg       0.25      0.49      0.33      3600\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1778\n",
      "           1       0.51      1.00      0.67      1822\n",
      "\n",
      "    accuracy                           0.51      3600\n",
      "   macro avg       0.25      0.50      0.34      3600\n",
      "weighted avg       0.26      0.51      0.34      3600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(oneY_test, LRmodelOne.predict(oneX_test)))\n",
    "print(classification_report(twoY_test, LRmodelTwo.predict(twoX_test)))\n",
    "print(classification_report(threeY_test, LRmodelThree.predict(threeX_test)))\n",
    "print(classification_report(fourY_test, LRmodelFour.predict(fourX_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "5e90b5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50763686, 0.49236314],\n",
       "       [0.50763686, 0.49236314],\n",
       "       [0.50763686, 0.49236314],\n",
       "       ...,\n",
       "       [0.50763686, 0.49236314],\n",
       "       [0.50763686, 0.49236314],\n",
       "       [0.50763686, 0.49236314]])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logRegOne.best_estimator_.predict_proba(oneX_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d304be5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8702    0]\n",
      " [8808    0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(oneY_train, logRegOne.best_estimator_.predict(oneX_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b6426",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "db65c1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results: One 0.6078443330035845 Two: 0.6079159330507976 Three: 0.6089515474916861 Four 0.6100533607829208\n",
      "Best params: \n",
      "One {'C': 3.0, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': -1} \n",
      "Two: {'C': 3.0, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': -1} \n",
      "Three: {'C': 10.0, 'class_weight': None, 'gamma': 0.1, 'kernel': 'linear', 'max_iter': -1} \n",
      "Four {'C': 3.0, 'class_weight': None, 'gamma': 0.1, 'kernel': 'linear', 'max_iter': -1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'kernel': ['linear', 'rbf'], \n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'max_iter': [-1],\n",
    "        'C': [3.0, 5.0, 10.0],\n",
    "        'gamma': [0.1, 'auto']\n",
    "    },\n",
    "]\n",
    "\n",
    "# Classifier trained with dataset One\n",
    "svmOne = GridSearchCV(SVC(), params, n_jobs=-1, scoring='f1')\n",
    "svmOne.fit(datasets['one'], labels['one'], groups=groups)\n",
    "\n",
    "# Classifier trained with dataset Two\n",
    "svmTwo = GridSearchCV(SVC(), params, n_jobs=-1, scoring='f1')\n",
    "svmTwo.fit(datasets['two'], labels['two'], groups=groups)\n",
    "\n",
    "# Classifier trained with dataset Three\n",
    "svmThree = GridSearchCV(SVC(), params, n_jobs=-1, scoring='f1')\n",
    "svmThree.fit(datasets['three'], labels['three'], groups=groupsEightyFive)\n",
    "\n",
    "# Classifier trained with dataset Four\n",
    "svmFour = GridSearchCV(SVC(), params, n_jobs=-1, scoring='f1')\n",
    "svmFour.fit(datasets['four'], labels['four'], groups=groupsEightyFive)\n",
    "\n",
    "print(f\"Best results: One {svmOne.best_score_} Two: {svmTwo.best_score_} Three: {svmThree.best_score_} Four {svmFour.best_score_}\")\n",
    "\n",
    "print(f\"Best params: \\nOne {svmOne.best_params_} \\nTwo: {svmTwo.best_params_} \\nThree: {svmThree.best_params_} \\nFour {svmFour.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "8ae066e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3.0, gamma=0.1, kernel='linear')"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVMmodelOne = SVC(**{'C': 3.0, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': -1})\n",
    "SVMmodelTwo = SVC(**{'C': 3.0, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': -1})\n",
    "SVMmodelThree = SVC(**{'C': 10.0, 'class_weight': None, 'gamma': 0.1, 'kernel': 'linear', 'max_iter': -1})\n",
    "SVMmodelFour = SVC(**{'C': 3.0, 'class_weight': None, 'gamma': 0.1, 'kernel': 'linear', 'max_iter': -1})\n",
    "\n",
    "# Train the models\n",
    "SVMmodelOne.fit(oneX_train, oneY_train)\n",
    "SVMmodelTwo.fit(twoX_train, twoY_train)\n",
    "SVMmodelThree.fit(threeX_train, threeY_train)\n",
    "SVMmodelFour.fit(fourX_train, fourY_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0041a771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.40      0.47      2242\n",
      "           1       0.52      0.70      0.60      2136\n",
      "\n",
      "    accuracy                           0.54      4378\n",
      "   macro avg       0.55      0.55      0.53      4378\n",
      "weighted avg       0.55      0.54      0.53      4378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.34      0.43      2265\n",
      "           1       0.51      0.73      0.60      2113\n",
      "\n",
      "    accuracy                           0.53      4378\n",
      "   macro avg       0.54      0.53      0.51      4378\n",
      "weighted avg       0.54      0.53      0.51      4378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.35      0.43      1782\n",
      "           1       0.53      0.72      0.61      1818\n",
      "\n",
      "    accuracy                           0.54      3600\n",
      "   macro avg       0.54      0.54      0.52      3600\n",
      "weighted avg       0.54      0.54      0.52      3600\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.37      0.44      1778\n",
      "           1       0.54      0.71      0.61      1822\n",
      "\n",
      "    accuracy                           0.54      3600\n",
      "   macro avg       0.54      0.54      0.53      3600\n",
      "weighted avg       0.54      0.54      0.53      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(oneY_test, SVMmodelOne.predict(oneX_test)))\n",
    "print(classification_report(twoY_test, SVMmodelTwo.predict(twoX_test)))\n",
    "print(classification_report(threeY_test, SVMmodelThree.predict(threeX_test)))\n",
    "print(classification_report(fourY_test, SVMmodelFour.predict(fourX_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffe263",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "709ade82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results: One 0.5992634826441268 Two: 0.5950955510592764 Three: 0.5958644650679255 Four 0.589312955717371\n",
      "Best params: \n",
      "One {'activation': 'logistic', 'alpha': 0.001, 'early_stopping': True, 'hidden_layer_sizes': (10,), 'max_iter': 10000, 'solver': 'adam'} \n",
      "Two: {'activation': 'relu', 'alpha': 0.001, 'early_stopping': True, 'hidden_layer_sizes': (20,), 'max_iter': 10000, 'solver': 'adam'} \n",
      "Three: {'activation': 'logistic', 'alpha': 0.0001, 'early_stopping': True, 'hidden_layer_sizes': (10,), 'max_iter': 10000, 'solver': 'adam'} \n",
      "Four {'activation': 'logistic', 'alpha': 0.001, 'early_stopping': True, 'hidden_layer_sizes': (20,), 'max_iter': 10000, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'hidden_layer_sizes': [\n",
    "            (10,),\n",
    "            (20,),\n",
    "        ], \n",
    "        'activation': ['relu', 'logistic'],  \n",
    "        'solver': ['lbfgs', 'adam'],\n",
    "        'max_iter': [10000],\n",
    "        'alpha': [0.0001, 0.001],\n",
    "        'early_stopping': [True]\n",
    "    }, \n",
    "]\n",
    "\n",
    "# Classifier trained with dataset One\n",
    "MLPOne = GridSearchCV(MLPClassifier(), params, n_jobs=-1, scoring='f1')\n",
    "MLPOne.fit(datasets['one'], labels['one'], groups=groups)\n",
    "\n",
    "# Classifier trained with dataset Two\n",
    "MLPTwo = GridSearchCV(MLPClassifier(), params, n_jobs=-1, scoring='f1')\n",
    "MLPTwo.fit(datasets['two'], labels['two'], groups=groups)\n",
    "\n",
    "# Classifier trained with dataset Three\n",
    "MLPThree = GridSearchCV(MLPClassifier(), params, n_jobs=-1, scoring='f1')\n",
    "MLPThree.fit(datasets['three'], labels['three'], groups=groupsEightyFive)\n",
    "\n",
    "# Classifier trained with dataset Four\n",
    "MLPFour = GridSearchCV(MLPClassifier(), params, n_jobs=-1, scoring='f1')\n",
    "MLPFour.fit(datasets['four'], labels['four'], groups=groupsEightyFive)\n",
    "\n",
    "print(f\"Best results: One {MLPOne.best_score_} Two: {MLPTwo.best_score_} Three: {MLPThree.best_score_} Four {MLPFour.best_score_}\")\n",
    "\n",
    "print(f\"Best params: \\nOne {MLPOne.best_params_} \\nTwo: {MLPTwo.best_params_} \\nThree: {MLPThree.best_params_} \\nFour {MLPFour.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7cf77b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.001, early_stopping=True,\n",
       "              hidden_layer_sizes=(20,), max_iter=10000)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPmodelOne = MLPClassifier(**{'activation': 'logistic', 'alpha': 0.001, 'early_stopping': True, 'hidden_layer_sizes': (10,), 'max_iter': 10000, 'solver': 'adam'})\n",
    "MLPmodelTwo = MLPClassifier(**{'activation': 'relu', 'alpha': 0.001, 'early_stopping': True, 'hidden_layer_sizes': (20,), 'max_iter': 10000, 'solver': 'adam'})\n",
    "MLPmodelThree = MLPClassifier(**{'activation': 'logistic', 'alpha': 0.0001, 'early_stopping': True, 'hidden_layer_sizes': (10,), 'max_iter': 10000, 'solver': 'adam'})\n",
    "MLPmodelFour = MLPClassifier(**{'activation': 'logistic', 'alpha': 0.001, 'early_stopping': True, 'hidden_layer_sizes': (20,), 'max_iter': 10000, 'solver': 'adam'})\n",
    "\n",
    "# Train the models\n",
    "MLPmodelOne.fit(oneX_train, oneY_train)\n",
    "MLPmodelTwo.fit(twoX_train, twoY_train)\n",
    "MLPmodelThree.fit(threeX_train, threeY_train)\n",
    "MLPmodelFour.fit(fourX_train, fourY_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "47eb6165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.45      0.50      2242\n",
      "           1       0.52      0.62      0.56      2136\n",
      "\n",
      "    accuracy                           0.53      4378\n",
      "   macro avg       0.53      0.53      0.53      4378\n",
      "weighted avg       0.54      0.53      0.53      4378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.40      0.47      2265\n",
      "           1       0.51      0.67      0.58      2113\n",
      "\n",
      "    accuracy                           0.53      4378\n",
      "   macro avg       0.54      0.53      0.52      4378\n",
      "weighted avg       0.54      0.53      0.52      4378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.39      0.45      1782\n",
      "           1       0.53      0.67      0.59      1818\n",
      "\n",
      "    accuracy                           0.53      3600\n",
      "   macro avg       0.53      0.53      0.52      3600\n",
      "weighted avg       0.53      0.53      0.52      3600\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.56      0.55      1778\n",
      "           1       0.55      0.52      0.54      1822\n",
      "\n",
      "    accuracy                           0.54      3600\n",
      "   macro avg       0.54      0.54      0.54      3600\n",
      "weighted avg       0.54      0.54      0.54      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(oneY_test, MLPmodelOne.predict(oneX_test)))\n",
    "print(classification_report(twoY_test, MLPmodelTwo.predict(twoX_test)))\n",
    "print(classification_report(threeY_test, MLPmodelThree.predict(threeX_test)))\n",
    "print(classification_report(fourY_test, MLPmodelFour.predict(fourX_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e76ba",
   "metadata": {},
   "source": [
    "### Random Froest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f02a197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results: One 0.5739777559448711 Two: 0.5713140817865076 Three: 0.5701883793694845 Four 0.5665810855681934\n",
      "Best params: \n",
      "One {'max_features': 'auto', 'n_estimators': 1600, 'n_jobs': -1} \n",
      "Two: {'max_features': 8, 'n_estimators': 1600, 'n_jobs': -1} \n",
      "Three: {'max_features': 'auto', 'n_estimators': 800, 'n_jobs': -1} \n",
      "Four {'max_features': 8, 'n_estimators': 1600, 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'n_estimators': [800, 1600],\n",
    "        'n_jobs': [-1],\n",
    "        'max_features': [8, 10, 'auto']\n",
    "    },\n",
    "]\n",
    "\n",
    "# Classifier trained with dataset One\n",
    "forestOne = GridSearchCV(RandomForestClassifier(), params, n_jobs=-1, scoring='f1')\n",
    "forestOne.fit(datasets['one'], labels['one'], groups=groups)\n",
    "\n",
    "# Classifier trained with dataset Two\n",
    "forestTwo = GridSearchCV(RandomForestClassifier(), params, n_jobs=-1, scoring='f1')\n",
    "forestTwo.fit(datasets['two'], labels['two'], groups=groups)\n",
    "\n",
    "# Classifier trained with dataset Three\n",
    "forestThree = GridSearchCV(RandomForestClassifier(), params, n_jobs=-1, scoring='f1')\n",
    "forestThree.fit(datasets['three'], labels['three'], groups=groupsEightyFive)\n",
    "\n",
    "# Classifier trained with dataset Four\n",
    "forestFour = GridSearchCV(RandomForestClassifier(), params, n_jobs=-1, scoring='f1')\n",
    "forestFour.fit(datasets['four'], labels['four'], groups=groupsEightyFive)\n",
    "\n",
    "print(f\"Best results: One {forestOne.best_score_} Two: {forestTwo.best_score_} Three: {forestThree.best_score_} Four {forestFour.best_score_}\")\n",
    "\n",
    "print(f\"Best params: \\nOne {forestOne.best_params_} \\nTwo: {forestTwo.best_params_} \\nThree: {forestThree.best_params_} \\nFour {forestFour.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0c48ee66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=8, n_estimators=1600, n_jobs=-1)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFmodelOne = RandomForestClassifier(**{'max_features': 'auto', 'n_estimators': 1600, 'n_jobs': -1})\n",
    "RFmodelTwo = RandomForestClassifier(**{'max_features': 8, 'n_estimators': 1600, 'n_jobs': -1})\n",
    "RFmodelThree = RandomForestClassifier(**{'max_features': 'auto', 'n_estimators': 800, 'n_jobs': -1})\n",
    "RFmodelFour = RandomForestClassifier(**{'max_features': 8, 'n_estimators': 1600, 'n_jobs': -1})\n",
    "\n",
    "# Train the models\n",
    "RFmodelOne.fit(oneX_train, oneY_train)\n",
    "RFmodelTwo.fit(twoX_train, twoY_train)\n",
    "RFmodelThree.fit(threeX_train, threeY_train)\n",
    "RFmodelFour.fit(fourX_train, fourY_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "96dce703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.49      0.53      2242\n",
      "           1       0.54      0.63      0.58      2136\n",
      "\n",
      "    accuracy                           0.56      4378\n",
      "   macro avg       0.56      0.56      0.56      4378\n",
      "weighted avg       0.56      0.56      0.56      4378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.49      0.54      2265\n",
      "           1       0.54      0.63      0.58      2113\n",
      "\n",
      "    accuracy                           0.56      4378\n",
      "   macro avg       0.56      0.56      0.56      4378\n",
      "weighted avg       0.56      0.56      0.56      4378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.51      0.53      1782\n",
      "           1       0.56      0.60      0.58      1818\n",
      "\n",
      "    accuracy                           0.56      3600\n",
      "   macro avg       0.56      0.56      0.55      3600\n",
      "weighted avg       0.56      0.56      0.56      3600\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.52      0.54      1778\n",
      "           1       0.56      0.60      0.58      1822\n",
      "\n",
      "    accuracy                           0.56      3600\n",
      "   macro avg       0.56      0.56      0.56      3600\n",
      "weighted avg       0.56      0.56      0.56      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(oneY_test, RFmodelOne.predict(oneX_test)))\n",
    "print(classification_report(twoY_test, RFmodelTwo.predict(twoX_test)))\n",
    "print(classification_report(threeY_test, RFmodelThree.predict(threeX_test)))\n",
    "print(classification_report(fourY_test, RFmodelFour.predict(fourX_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca709e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
